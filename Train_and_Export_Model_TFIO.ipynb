{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from IPython import display\n",
    "\n",
    "from DLHelperFunctions_TFIO import *\n",
    "\n",
    "import librosa.display\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "import absl.logging\n",
    "absl.logging.set_verbosity(absl.logging.ERROR)\n",
    "\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set the seed value for experiment reproducibility.\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set the dataset path\n",
    "OPUS_DATASET_PATH = './data/mswc_microset/'\n",
    "WAV_DATASET_PATH = './data/mswc_microset_wav/'\n",
    "TRIMD_DATASET_PATH = './data/mswc_microset_trimd/'\n",
    "\n",
    "# Download the dataset\n",
    "opus_dir = pathlib.Path(OPUS_DATASET_PATH)\n",
    "wav_dir = pathlib.Path(WAV_DATASET_PATH)\n",
    "trimd_dir = pathlib.Path(TRIMD_DATASET_PATH)\n",
    "if not opus_dir.exists():\n",
    "    tf.keras.utils.get_file(\n",
    "        'mswc_microset.tar.gz',\n",
    "        origin=\"https://storage.googleapis.com/public-datasets-mswc/mswc_microset.tar.gz\",\n",
    "        extract=True,\n",
    "        cache_dir='.', cache_subdir='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert OPUS to WAV & Reformat the directories\n",
    "wav_ds = os.path.join(wav_dir, 'clips/')\n",
    "\n",
    "if not os.path.exists(wav_dir):\n",
    "    os.makedirs(wav_dir)\n",
    "    if not os.path.exists(wav_ds):\n",
    "        os.makedirs(wav_ds)\n",
    "\n",
    "    en_opus_path = os.path.join(opus_dir, 'en/clips/')\n",
    "    es_opus_path = os.path.join(opus_dir, 'es/clips/')\n",
    "\n",
    "    opus_to_wav(en_opus_path, wav_ds)\n",
    "    opus_to_wav(es_opus_path, wav_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Trim Audio of silence and store\n",
    "trmd_ds = os.path.join(trimd_dir, 'clips/')\n",
    "\n",
    "if not os.path.exists(trimd_dir):\n",
    "    os.makedirs(trimd_dir)\n",
    "    if not os.path.exists(trmd_ds):\n",
    "        os.makedirs(trmd_ds)\n",
    "\n",
    "    for word in os.listdir(wav_ds):\n",
    "        wav_word_path = os.path.join(wav_ds, word)\n",
    "        print(\"Trimming WAVs of \\\"\" + word + \"\\\" class\")\n",
    "        print('++++++++++++++++++++++++++++++++++')\n",
    "        new_wav_word_path = os.path.join(trmd_ds, word)\n",
    "        os.makedirs(new_wav_word_path)\n",
    "        for wav in os.listdir(wav_word_path):\n",
    "            cur_wav = os.path.join(wav_word_path, wav)\n",
    "            new_cur_wav = os.path.join(new_wav_word_path, \"t_\" + wav)\n",
    "            t_wav, sr = trim_audio(cur_wav)\n",
    "            #open(os.path.join(trmd_ds, t_name), 'a').close()\n",
    "            sf.write(new_cur_wav, t_wav, sr, format='wav')\n",
    "    print('DONE!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print the Classification Commands of the Dataset\n",
    "words = np.array(tf.io.gfile.listdir(wav_ds))\n",
    "#words = np.array(tf.io.gfile.listdir(trmd_ds))\n",
    "words = np.sort(words)\n",
    "print('Words:', words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sr = 20000\n",
    "sr = 45000\n",
    "\n",
    "train_ds, val_ds = tf.keras.utils.audio_dataset_from_directory(\n",
    "    directory=wav_ds,\n",
    "    #directory=trmd_ds,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    seed=0,\n",
    "    output_sequence_length=sr,\n",
    "    subset='both')\n",
    "\n",
    "label_names = np.array(train_ds.class_names)\n",
    "print()\n",
    "print(\"label names:\", label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_ds = train_ds.map(squeeze, tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.map(squeeze, tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_ds = val_ds.shard(num_shards=2, index=0)\n",
    "val_ds = val_ds.shard(num_shards=2, index=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for example_audio, example_labels in train_ds.take(1):\n",
    "  print(example_audio.shape)\n",
    "  print(example_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rows = 3\n",
    "cols = 3\n",
    "n = rows * cols\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(16, 9))\n",
    "\n",
    "for i in range(n):\n",
    "  if i>=n:\n",
    "    break\n",
    "  r = i // cols\n",
    "  c = i % cols\n",
    "  ax = axes[r][c]\n",
    "  ax.plot(example_audio[i].numpy())\n",
    "  ax.set_yticks(np.arange(-1.2, 1.2, 0.2))\n",
    "  label = label_names[example_labels[i]]\n",
    "  ax.set_title(label)\n",
    "  ax.set_ylim([-1.1,1.1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from DLHelperFunctions_TFIO import *\n",
    "for i in range(3):\n",
    "  label = label_names[example_labels[i]]\n",
    "  waveform = example_audio[i]\n",
    "  spectrogram = get_spectrogram(waveform)\n",
    "\n",
    "  print('Label:', label)\n",
    "  print('Waveform shape:', waveform.shape)\n",
    "  print('Spectrogram shape:', spectrogram.shape)\n",
    "  print('Audio playback')\n",
    "  display.display(display.Audio(waveform, rate=sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, figsize=(12, 8))\n",
    "timescale = np.arange(waveform.shape[0])\n",
    "axes[0].plot(timescale, waveform.numpy())\n",
    "axes[0].set_title('Waveform')\n",
    "axes[0].set_xlim([0, sr])\n",
    "\n",
    "plot_spectrogram(spectrogram.numpy(), axes[1])\n",
    "axes[1].set_title('Spectrogram')\n",
    "plt.suptitle(label.title())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add Dataset.cache and Dataset.prefetch operations to reduce read latency while training the model\n",
    "train_ds = train_ds.cache().shuffle(10000).prefetch(tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.cache().prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_spectrogram_ds = make_spec_ds(train_ds)\n",
    "val_spectrogram_ds = make_spec_ds(val_ds)\n",
    "test_spectrogram_ds = make_spec_ds(test_ds)\n",
    "\n",
    "# train_spectrogram_ds = make_melspec_ds(train_ds,sr)\n",
    "# val_spectrogram_ds = make_melspec_ds(val_ds,sr)\n",
    "# test_spectrogram_ds = make_melspec_ds(test_ds,sr)\n",
    "\n",
    "# train_spectrogram_ds = train_spectrogram_ds.concatenate(make_melspec_ds(train_ds,sr))\n",
    "# val_spectrogram_ds = val_spectrogram_ds.concatenate(make_melspec_ds(val_ds,sr))\n",
    "# test_spectrogram_ds = test_spectrogram_ds.concatenate(make_melspec_ds(test_ds,sr))\n",
    "\n",
    "# train_spectrogram_ds = train_spectrogram_ds.concatenate(make_melspec_db(train_ds,sr))\n",
    "# val_spectrogram_ds = val_spectrogram_ds.concatenate(make_melspec_db(val_ds,sr))\n",
    "# test_spectrogram_ds = test_spectrogram_ds.concatenate(make_melspec_db(test_ds,sr))\n",
    "\n",
    "# train_spectrogram_ds = train_spectrogram_ds.concatenate(make_mfcc_ds(train_ds,sr))\n",
    "# val_spectrogram_ds = val_spectrogram_ds.concatenate(make_mfcc_ds(val_ds,sr))\n",
    "# test_spectrogram_ds = test_spectrogram_ds.concatenate(make_mfcc_ds(test_ds,sr))\n",
    "\n",
    "# train_spectrogram_ds = make_four_ds(train_ds,sr)\n",
    "# val_spectrogram_ds = make_four_ds(val_ds,sr)\n",
    "# test_spectrogram_ds = make_four_ds(test_ds,sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_spectrogram_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for example_spectrograms, example_spect_labels in train_spectrogram_ds.take(1):\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rows = 3\n",
    "cols = 3\n",
    "n = rows*cols\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(16, 9))\n",
    "\n",
    "for i in range(n):\n",
    "    r = i // cols\n",
    "    c = i % cols\n",
    "    ax = axes[r][c]\n",
    "    plot_spectrogram(example_spectrograms[i].numpy(), ax)\n",
    "    ax.set_title(words[example_spect_labels[i].numpy()])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_spectrogram_ds = train_spectrogram_ds.cache().shuffle(10000).prefetch(tf.data.AUTOTUNE)\n",
    "val_spectrogram_ds = val_spectrogram_ds.cache().prefetch(tf.data.AUTOTUNE)\n",
    "test_spectrogram_ds = test_spectrogram_ds.cache().prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "input_shape = example_spectrograms.shape[1:]\n",
    "print('Input shape:', input_shape)\n",
    "num_labels = len(words)\n",
    "\n",
    "# Instantiate the `tf.keras.layers.Normalization` layer.\n",
    "norm_layer = layers.Normalization()\n",
    "# Fit the state of the layer to the spectrograms\n",
    "# with `Normalization.adapt`.\n",
    "norm_layer.adapt(data=train_spectrogram_ds.map(map_func=lambda spec, label: spec))\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=input_shape),\n",
    "    # Downsample the input.\n",
    "    layers.Resizing(32, 32),\n",
    "    # Normalize.\n",
    "    norm_layer,\n",
    "    layers.Conv2D(32, 3, activation='relu'),\n",
    "    layers.Conv2D(64, 3, activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Dropout(0.25),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(num_labels),\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "history = model.fit(\n",
    "    train_spectrogram_ds,\n",
    "    validation_data=val_spectrogram_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=tf.keras.callbacks.EarlyStopping(verbose=1, patience=2),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "metrics = history.history\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.epoch, metrics['loss'], metrics['val_loss'])\n",
    "plt.legend(['loss', 'val_loss'])\n",
    "plt.ylim([0, max(plt.ylim())])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss [CrossEntropy]')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.epoch, 100*np.array(metrics['accuracy']), 100*np.array(metrics['val_accuracy']))\n",
    "plt.legend(['accuracy', 'val_accuracy'])\n",
    "plt.ylim([0, 100])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy [%]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model.evaluate(test_spectrogram_ds, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_spectrogram_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "y_pred = tf.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "y_true = tf.concat(list(test_spectrogram_ds.map(lambda s,lab: lab)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "confusion_mtx = tf.math.confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(20, 18))\n",
    "sns.heatmap(confusion_mtx,\n",
    "            xticklabels=words,\n",
    "            yticklabels=words,\n",
    "            annot=True, fmt='g')\n",
    "plt.xlabel('Prediction')\n",
    "plt.ylabel('Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "x = 'data/inference_samples/wow_sample.wav'\n",
    "x = tf.io.read_file(str(x))\n",
    "x, sample_rate = tf.audio.decode_wav(x, desired_channels=1, desired_samples=sr,)\n",
    "x = tf.squeeze(x, axis=-1)\n",
    "waveform = x\n",
    "x = get_spectrogram(x)\n",
    "x = x[tf.newaxis,...]\n",
    "\n",
    "prediction = model(x)\n",
    "plt.figure(figsize=(60,10))\n",
    "plt.bar(words, tf.nn.softmax(prediction[0]))\n",
    "plt.title('Wow')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "display.display(display.Audio(waveform, rate=sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Save model in \"./saved\"\n",
    "model.save(\"saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tf-py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "c4bb7afac8597c20637caf6f54724b14b6cf9e4d56fd32da9d2b0cee309b1256"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
